import os
import logging
import requests
import datetime
import json
import feedparser
import random
import re
from bs4 import BeautifulSoup
from aiogram import Bot, Dispatcher, executor, types
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
from dotenv import load_dotenv
from langdetect import detect

load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OWNER_IDS = {int(i) for i in os.getenv("OWNER_IDS", "").split(",") if i.strip().isdigit()}
PROXY_URL = os.getenv("PROXY_URL", "https://clandestino-proxy.onrender.com/v1/chat/completions")

bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher(bot)
logging.basicConfig(level=logging.INFO)

menu_keyboard = InlineKeyboardMarkup(row_width=2)
menu_keyboard.add(
    InlineKeyboardButton("üì∞ –ù–æ–≤–æ—Å—Ç–∏", callback_data="news"),
    InlineKeyboardButton("üé® –≠—Å—Ç–µ—Ç–∏–∫–∞", callback_data="aesthetics"),
    InlineKeyboardButton("‚ú® –¶–∏—Ç–∞—Ç–∞", callback_data="quote"),
    InlineKeyboardButton("üí¨ –ò—Å—Ç–æ—Ä–∏—è", callback_data="story")
)

post_actions_keyboard = InlineKeyboardMarkup(row_width=2)
post_actions_keyboard.add(
    InlineKeyboardButton("üîÅ –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å", callback_data="rewrite"),
    InlineKeyboardButton("üì§ –û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –≤ –í–ö", callback_data="post_vk"),
    InlineKeyboardButton("üîÑ –•–æ—á—É –µ—â—ë", callback_data="next_post")
)

user_cache = {}

BLOCKED_KEYWORDS = ["—Ä–µ–∫–ª–∞–º–∞", "–∫—É–ø–∏—Ç—å", "—Å–∫–∏–¥–∫–∞", "–ø–æ–¥–ø–∏—à–∏—Å—å", "–±—Ä–µ–Ω–¥", "–∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä"]
BLOCKED_NAMES = ["local influencer", "—Ä–µ–∫–ª–∞–º–æ–¥–∞—Ç–µ–ª—å", "–±—Ä–µ–Ω–¥"]
FOCUS_KEYWORDS = [
    "–∑–≤–µ–∑–¥–∞", "—Å–µ–ª–µ–±—Ä–∏—Ç–∏", "–∞–∫—Ç—ë—Ä", "–ø–µ–≤–µ—Ü", "–ø–µ–≤–∏—Ü–∞", "—à–æ—É–±–∏–∑–Ω–µ—Å", "—à–æ—É-–±–∏–∑–Ω–µ—Å",
    "–º–æ–¥–Ω—ã–π –ø–æ–∫–∞–∑", "–∏–Ω—Ç–µ—Ä–≤—å—é", "–∫—Ä–∞—Å–Ω–∞—è –¥–æ—Ä–æ–∂–∫–∞", "–≥–æ–ª–ª–∏–≤—É–¥", "–≤–µ–¥—É—â–∞—è", "–º–æ–¥–µ–ª—å", "–±–ª–æ–≥–µ—Ä"
]

RSS_FEEDS = [
    "https://www.elle.ru/rss/all/",
    "https://www.harpersbazaar.com/rss/",
    "https://www.vogue.com/feed/rss",
    "https://people.com/feed/",
    "https://www.hollywoodreporter.com/t/feed/",
    "https://www.glamourmagazine.co.uk/rss",
    "https://www.etonline.com/news/rss"
]

def is_foreign(text):
    try:
        return detect(text) != "ru"
    except:
        return False

def clean_html(text):
    soup = BeautifulSoup(text, "html.parser")
    return soup.get_text()

def sanitize_text(text):
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def is_advertisement(text):
    text = text.lower()
    return any(keyword in text for keyword in BLOCKED_KEYWORDS) or any(name.lower() in text for name in BLOCKED_NAMES)

def is_on_topic(text):
    text = text.lower()
    return any(keyword in text for keyword in FOCUS_KEYWORDS)

def translate_and_adapt(text, category="news"):
    if is_foreign(text):
        prompt = (
            "–ü–µ—Ä–µ–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–π –µ–≥–æ –ø–æ–¥ —Å—Ç–∏–ª—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π VK-–≥—Ä—É–ø–ø—ã –æ –∑–≤–µ–∑–¥–∞—Ö –∏ –º–æ–¥–µ. "
            "–¢–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –ë–µ–∑ HTML. –ë–µ–∑ —Ä–µ–∫–ª–∞–º–Ω—ã—Ö —Ñ—Ä–∞–∑. –ë–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –º–∞–ª–æ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω. "
            "–ù–∞–ø–∏—à–∏ –ª–∞–∫–æ–Ω–∏—á–Ω–æ, —Å—Ç–∏–ª—å–Ω–æ, 1-4 –∞–±–∑–∞—Ü–∞. –£–¥–∞–ª–∏ –º—É—Å–æ—Ä. –§–æ–∫—É—Å ‚Äî —à–æ—É-–±–∏–∑–Ω–µ—Å, –º–æ–¥–∞, –∑–≤–µ–∑–¥—ã –≤—ã—Å–æ–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è."
            f"\n\n{text}"
        )
    else:
        if category == "quote":
            prompt = (
                "–°–¥–µ–ª–∞–π —Ä–µ—Ä–∞–π—Ç —Ü–∏—Ç–∞—Ç—ã –æ—Ç –∏–º–µ–Ω–∏ –∑–≤–µ–∑–¥—ã. –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç–∏–ª—å, —Ö–∞—Ä–∏–∑–º—É, –∫—Ä–∞—Ç–∫–æ—Å—Ç—å. –ë–µ–∑ HTML, –±–µ–∑ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö —Å–ª–æ–≤."
                f"\n\n{text}"
            )
        elif category == "aesthetics":
            prompt = (
                "–û–ø–∏—à–∏ —ç—Å—Ç–µ—Ç–∏–∫—É —Ñ–æ—Ç–æ –∏–ª–∏ —Å–æ–±—ã—Ç–∏—è –≤ –¥—É—Ö–µ –º–æ–¥–Ω–æ–π VK-–≥—Ä—É–ø–ø—ã. –°–æ—Ö—Ä–∞–Ω–∏ –æ–±—Ä–∞–∑–Ω–æ—Å—Ç—å –∏ –∞—Ç–º–æ—Å—Ñ–µ—Ä—É. –ë–µ–∑ HTML."
                f"\n\n{text}"
            )
        elif category == "story":
            prompt = (
                "–ü–µ—Ä–µ–ø–∏—à–∏ —ç—Ç—É –∏—Å—Ç–æ—Ä–∏—é, —Å–¥–µ–ª–∞–π –µ—ë –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–µ–π –∏ –ª–∞–∫–æ–Ω–∏—á–Ω–æ–π. –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–æ—Å—Ç–∞ –≤ VK-–≥—Ä—É–ø–ø—É –æ —à–æ—É-–±–∏–∑–Ω–µ—Å–µ."
                f"\n\n{text}"
            )
        else:
            prompt = (
                "–°–¥–µ–ª–∞–π —Ä–µ—Ä–∞–π—Ç —Ç–µ–∫—Å—Ç–∞ –≤ —Å—Ç–∏–ª–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ–π VK-–≥—Ä—É–ø–ø—ã: –ª–∞–∫–æ–Ω–∏—á–Ω–æ, –¥–µ—Ä–∑–∫–æ, —ç—Å—Ç–µ—Ç–∏—á–Ω–æ, "
                "–æ—Ç 1 –¥–æ 4 –∞–±–∑–∞—Ü–µ–≤. –£–¥–∞–ª–∏ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ —Ñ—Ä–∞–∑—ã, HTML, —Ä–µ–∫–ª–∞–º–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –º–∞–ª–æ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∏–º–µ–Ω–∞. "
                "–§–æ–∫—É—Å = –∑–≤–µ–∑–¥—ã, —Ç–µ–ª–µ–≤–µ–¥—É—â–∏–µ, –∞–∫—Ç–µ—Ä—ã, –ø–µ–≤—Ü—ã, –∑–Ω–∞–º–µ–Ω–∏—Ç–æ—Å—Ç–∏ –º–∏—Ä–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è."
                f"\n\n{text}"
            )

    response = requests.post(
        PROXY_URL,
        headers={"Content-Type": "application/json"},
        json={
            "model": "gpt-3.5-turbo",
            "messages": [{"role": "user", "content": prompt}]
        }
    )
    if response.ok:
        data = response.json()
        return data["choices"][0]["message"]["content"].strip()
    else:
        logging.error(f"–û—à–∏–±–∫–∞ GPT: {response.text}")
        return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ/–∞–¥–∞–ø—Ç–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞."

def parse_rss(category):
    all_entries = []
    for url in RSS_FEEDS:
        feed = feedparser.parse(url)
        for entry in feed.entries:
            text = clean_html(entry.get("summary", "") or entry.get("description", ""))
            title = entry.get("title", "")
            combined_text = f"{title}\n{text}"
            if not is_advertisement(combined_text) and (is_on_topic(combined_text) or category != "news"):
                all_entries.append(combined_text)
    if not all_entries and category == "news":
        for url in RSS_FEEDS:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                text = clean_html(entry.get("summary", "") or entry.get("description", ""))
                title = entry.get("title", "")
                combined_text = f"{title}\n{text}"
                if not is_advertisement(combined_text):
                    all_entries.append(combined_text)
    random.shuffle(all_entries)
    return all_entries

@dp.message_handler(commands=['start'])
async def send_welcome(message: types.Message):
    await message.answer("–í—ã–±–µ—Ä–∏ —Ç–∏–ø –ø–æ—Å—Ç–∞:", reply_markup=menu_keyboard)

@dp.callback_query_handler(lambda c: c.data in ["news", "aesthetics", "quote", "story"])
async def handle_category(callback_query: types.CallbackQuery):
    category = callback_query.data
    await bot.answer_callback_query(callback_query.id)

    all_texts = parse_rss(category)
    if not all_texts:
        await bot.send_message(callback_query.from_user.id, "–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
        return

    adapted = translate_and_adapt(all_texts[0], category)
    user_cache[callback_query.from_user.id] = {"texts": all_texts[1:], "category": category}

    await bot.send_message(callback_query.from_user.id, f"–°–æ–±—Ä–∞–Ω —Ç–µ–∫—Å—Ç:\n\n{adapted}", reply_markup=post_actions_keyboard)

@dp.callback_query_handler(lambda c: c.data == "next_post")
async def handle_next(callback_query: types.CallbackQuery):
    cache = user_cache.get(callback_query.from_user.id, {})
    texts = cache.get("texts", [])
    category = cache.get("category", "news")
    if not texts:
        await bot.send_message(callback_query.from_user.id, "–ù–æ–≤–æ—Å—Ç–µ–π –±–æ–ª—å—à–µ –Ω–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞ –ø–æ–∑–∂–µ.")
        return
    next_text = texts.pop(0)
    user_cache[callback_query.from_user.id] = {"texts": texts, "category": category}
    adapted = translate_and_adapt(next_text, category)
    await bot.send_message(callback_query.from_user.id, f"–°–æ–±—Ä–∞–Ω —Ç–µ–∫—Å—Ç:\n\n{adapted}", reply_markup=post_actions_keyboard)

@dp.callback_query_handler(lambda c: c.data == "rewrite")
async def handle_rewrite(callback_query: types.CallbackQuery):
    cache = user_cache.get(callback_query.from_user.id, {})
    texts = cache.get("texts", [])
    category = cache.get("category", "news")
    if not texts:
        await bot.send_message(callback_query.from_user.id, "–ù–µ—á–µ–≥–æ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å.")
        return
    original = texts[0]
    rewritten = translate_and_adapt(original, category)
    await bot.send_message(callback_query.from_user.id, f"–í–∞—Ä–∏–∞–Ω—Ç –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏:\n\n{rewritten}", reply_markup=post_actions_keyboard)

if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)
    executor.start_polling(dp, skip_updates=True)



